<!doctype html>
<html lang="en">

    <head>

		<!-- Required meta tags -->
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

        <title>surfify</title>
        
        <!-- CSS -->
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:100,300,400,500&display=swap">
		<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
        <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
        <link rel="stylesheet" href="../../../_static/css/jquery.mCustomScrollbar.min.css">
        <link rel="stylesheet" href="../../../_static/css/animate.css">
        <link rel="stylesheet" href="../../../_static/css/style.css">
        <link rel="stylesheet" href="../../../_static/css/jquery.mosaic.css">
        <link rel="stylesheet" href="../../../_static/sg_gallery.css">
        <link rel="stylesheet" href="../../../_static/css/media-queries.css">
        <link rel="stylesheet" href="../../../_static/css/pygment.css">

        <!-- Favicon and touch icons -->
        <link rel="shortcut icon" href="../../../_static/ico/favicon.png">
        <link rel="apple-touch-icon-precomposed" sizes="144x144" href="../../../_static/ico/apple-touch-icon-144-precomposed.png">
        <link rel="apple-touch-icon-precomposed" sizes="114x114" href="../../../_static/ico/apple-touch-icon-114-precomposed.png">
        <link rel="apple-touch-icon-precomposed" sizes="72x72" href="../../../_static/ico/apple-touch-icon-72-precomposed.png">
        <link rel="apple-touch-icon-precomposed" href="../../../_static/ico/apple-touch-icon-57-precomposed.png">

    </head>

    <body>

		<!-- Wrapper -->
    	<div class="wrapper">

			<!-- Sidebar -->
			<nav class="sidebar">
				
				<!-- close sidebar menu -->
				<div class="dismiss">
					<i class="fas fa-arrow-left"></i>
				</div>
				
				<div class="logo"">
					<h3><a href="../../../index.html">Sidebar Menu</a></h3>
				</div>

                <!-- info setup -->
                    <p class="doc-version">
                        This documentation is for surfify <strong>version 0.3.0</strong>
                    </p>
                <p class="citing">
                    If you use the software, please do not hesitate to 
                    <a &mdash; <a href="https://github.com/neurospin-deepinsight/surfify">
                    Report a Bug</a>.
                </p>
				
                <!-- links -->
                
                
				<ul class="list-unstyled menu-elements">
					<li class="active">
						<a href="../../../index.html"><i class="fas fa-home"></i> Home</a>
					</li>
					<li>
						<a href="../../../generated/installation.html"><i class="fas fa-cog"></i> Installation</a>
					</li>
					<li>
						<a href="../../../auto_gallery/index.html"><i class="fas fa-eye"></i> Gallery</a>
					</li>
					<li>
						<a href="../../../generated/documentation.html"><i class="fas fa-pencil-alt"></i> API documentation</a>
					</li>
					<li>
						<a href="../../../generated/search.html"><i class="fas fa-search"></i> Search</a>
					</li>
					<li>
						<a href="https://joliot.cea.fr/drf/joliot/Pages/Entites_de_recherche/NeuroSpin.aspx"><i class="fas fa-external-link-alt"></i> NeuroSpin webPage</a>
					</li>
					<li>
						<a href="#otherSections" data-toggle="collapse" aria-expanded="false" class="dropdown-toggle" role="button" aria-controls="otherSections">
							<i class="fas fa-sync"></i>Sections Shortcuts
						</a>
						<ul class="collapse list-unstyled" id="otherSections">
                            <li>LINKS</li><li><a href='https://github.com/neurospin-deepinsight/deepinsight'>deepinsight</a></li>
                            
                            <li>API</li>
                            <li><a href="../../../generated/surfify.html">surfify</a></li><li><a href="../../../generated/surfify.augmentation.html">surfify.augmentation</a></li><li><a href="../../../generated/surfify.datasets.html">surfify.datasets</a></li><li><a href="../../../generated/surfify.losses.html">surfify.losses</a></li><li><a href="../../../generated/surfify.models.html">surfify.models</a></li><li><a href="../../../generated/surfify.nn.html">surfify.nn</a></li><li><a href="../../../generated/surfify.plotting.html">surfify.plotting</a></li><li><a href="../../../generated/surfify.utils.html">surfify.utils</a></li>
						</ul>
					</li>
				</ul>
				
                <!-- go top page -->
				<div class="to-top">
					<a class="btn btn-primary btn-customized-3" href="#" role="button">
	                    <i class="fas fa-arrow-up"></i> Top
	                </a>
				</div>
			
                <!-- change color -->
				<div class="dark-light-buttons">
					<a class="btn btn-primary btn-customized-4 btn-customized-dark" href="#" role="button">Dark</a>
					<a class="btn btn-primary btn-customized-4 btn-customized-light" href="#" role="button">Light</a>
				</div>
			
			</nav>
			<!-- End sidebar -->
			
			<!-- Dark overlay -->
    		<div class="overlay"></div>

			<!-- Content -->
			<div class="content">
			
				<!-- open sidebar menu -->
				<a class="btn btn-primary btn-customized open-menu" href="#" role="button">
                    <i class="fas fa-align-left"></i> <span>Menu</span>
                </a>

		        <!-- Top content -->
		        <div class="top-content section-container" id="top-content">
			        <div class="container">
			            <div class="row">
                            <div class="col-md-3 section-5-box banner-logo">
                                <img alt="Logo" src="../../../_static/surfify.png">
                            </div>
			                <div class="col-md-7 section-5-box">
			                	<h1 class="wow fadeIn">    <p>PyTorch toolbox to work with spherical surfaces.</p></h1>
			                </div>
			            </div>
			        </div>
		        </div>
                    
                    <div class="document">
                        <h1>Source code for surfify.models.vae</h1><div class='divider-1 wow fadeInUp'><span></span></div><div class="highlight"><pre>
<span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="c1">##########################################################################</span>
<span class="c1"># NSAp - Copyright (C) CEA, 2021</span>
<span class="c1"># Distributed under the terms of the CeCILL-B license, as published by</span>
<span class="c1"># the CEA-CNRS-INRIA. Refer to the LICENSE file or to</span>
<span class="c1"># http://www.cecill.info/licences/Licence_CeCILL-B_V1-en.html</span>
<span class="c1"># for details.</span>
<span class="c1">##########################################################################</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Cortical Spherical Variational Auto-Encoder (GMVAE) models.</span>

<span class="sd">[1] Representation Learning of Resting State fMRI with Variational</span>
<span class="sd">Autoencoder: https://github.com/libilab/rsfMRI-VAE</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1"># Imports</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.distributions</span><span class="w"> </span><span class="kn">import</span> <span class="n">Normal</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="kn">import</span> <span class="n">sqrt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_logger</span><span class="p">,</span> <span class="n">debug_msg</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">IcoUpConv</span><span class="p">,</span> <span class="n">IcoPool</span><span class="p">,</span> <span class="n">IcoSpMaConv</span><span class="p">,</span> <span class="n">IcoSpMaConvTranspose</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">SphericalBase</span>


<span class="c1"># Global parameters</span>
<span class="n">logger</span> <span class="o">=</span> <span class="n">get_logger</span><span class="p">()</span>


<div class="viewcode-block" id="SphericalVAE">
<a class="viewcode-back" href="../../../generated/surfify.models.vae.SphericalVAE.html#surfify.models.SphericalVAE">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">SphericalVAE</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Spherical VAE architecture.</span>

<span class="sd">    Use either RePa - Rectangular Patch convolution method or DiNe - Direct</span>
<span class="sd">    Neighbor convolution method.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Debuging messages can be displayed by changing the log level using</span>
<span class="sd">    ``setup_logging(level=&#39;debug&#39;)``.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    SphericalGVAE</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    Representation Learning of Resting State fMRI with Variational</span>
<span class="sd">    Autoencoder, NeuroImage 2021.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; from surfify.utils import icosahedron</span>
<span class="sd">    &gt;&gt;&gt; from surfify.models import SphericalVAE</span>
<span class="sd">    &gt;&gt;&gt; verts, tris = icosahedron(order=6)</span>
<span class="sd">    &gt;&gt;&gt; x = torch.zeros((1, 2, len(verts)))</span>
<span class="sd">    &gt;&gt;&gt; model = SphericalVAE(</span>
<span class="sd">    &gt;&gt;&gt;     input_channels=2, input_order=6, latent_dim=64,</span>
<span class="sd">    &gt;&gt;&gt;     conv_flts=[32, 32, 64, 64], conv_mode=&quot;DiNe&quot;, dine_size=1,</span>
<span class="sd">    &gt;&gt;&gt;     fusion_level=2, standard_ico=False&quot;)</span>
<span class="sd">    &gt;&gt;&gt; print(model)</span>
<span class="sd">    &gt;&gt;&gt; out = model(x, x)</span>
<span class="sd">    &gt;&gt;&gt; print(out[0].shape, out[1].shape)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_order</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">192</span><span class="p">,</span>
                 <span class="n">latent_dim</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">conv_flts</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span> <span class="n">fusion_level</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;LeakyReLU&quot;</span><span class="p">,</span> <span class="n">batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">conv_mode</span><span class="o">=</span><span class="s2">&quot;DiNe&quot;</span><span class="p">,</span>
                 <span class="n">cachedir</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">encoder</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">decoder</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Init class.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        input_channels: int, default 1</span>
<span class="sd">            the number of input channels.</span>
<span class="sd">        input_order: int, default 5</span>
<span class="sd">            the input icosahedron order.</span>
<span class="sd">        latent_dim: int, default 64</span>
<span class="sd">            the size of the stochastic latent state of the SVAE.</span>
<span class="sd">        conv_flts: list of int</span>
<span class="sd">            the size of convolutional filters.</span>
<span class="sd">        conv_mode: str, default &#39;DiNe&#39;</span>
<span class="sd">            use either &#39;RePa&#39; - Rectangular Patch convolution method or &#39;DiNe&#39;</span>
<span class="sd">            - 1 ring Direct Neighbor convolution method.</span>
<span class="sd">        dine_size: int, default 1</span>
<span class="sd">            the size of the spherical convolution filter, ie. the number of</span>
<span class="sd">            neighbor rings to be considered.</span>
<span class="sd">        repa_size: int, default 5</span>
<span class="sd">            the size of the rectangular grid in the tangent space.</span>
<span class="sd">        repa_zoom: int, default 5</span>
<span class="sd">            control the rectangular grid spacing in the tangent space by</span>
<span class="sd">            applying a multiplicative factor of `1 / repa_zoom`.</span>
<span class="sd">        dynamic_repa_zoom: bool, default False</span>
<span class="sd">            dynamically adapt the RePa zoom by applying a multiplicative factor</span>
<span class="sd">            of `log(order + 1) + 1`.</span>
<span class="sd">        fusion_level: int, default 1</span>
<span class="sd">            at which max pooling level left and right hemisphere data</span>
<span class="sd">            are concatenated.</span>
<span class="sd">        standard_ico: bool, default False</span>
<span class="sd">            optionaly use surfify tesselation.</span>
<span class="sd">        cachedir: str, default None</span>
<span class="sd">            set this folder to use smart caching speedup.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;SphericalVAE init...&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">assert</span> <span class="n">conv_mode</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;DiNe&quot;</span><span class="p">,</span> <span class="s2">&quot;RePa&quot;</span><span class="p">,</span> <span class="s2">&quot;SpMa&quot;</span><span class="p">]</span>
        <span class="n">use_grid</span> <span class="o">=</span> <span class="n">conv_mode</span> <span class="o">==</span> <span class="s2">&quot;SpMa&quot;</span>
        <span class="k">if</span> <span class="n">use_grid</span> <span class="ow">and</span> <span class="n">encoder</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">encoder</span> <span class="o">=</span> <span class="n">HemiFusionEncoder</span><span class="p">(</span>
                <span class="n">input_channels</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">latent_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">conv_flts</span><span class="p">,</span>
                <span class="n">fusion_level</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span> <span class="n">batch_norm</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">encoder</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">encoder</span> <span class="o">=</span> <span class="n">SphericalHemiFusionEncoder</span><span class="p">(</span>
                <span class="n">input_channels</span><span class="p">,</span> <span class="n">input_order</span><span class="p">,</span> <span class="n">latent_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">conv_flts</span><span class="p">,</span>
                <span class="n">fusion_level</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span> <span class="n">batch_norm</span><span class="p">,</span> <span class="n">conv_mode</span><span class="p">,</span>
                <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">cachedir</span><span class="o">=</span><span class="n">cachedir</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">use_grid</span> <span class="ow">and</span> <span class="n">decoder</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">decoder</span> <span class="o">=</span> <span class="n">HemiFusionDecoder</span><span class="p">(</span>
                <span class="p">[</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">],</span> <span class="n">encoder</span><span class="o">.</span><span class="n">flatten_dim</span><span class="p">,</span>
                <span class="n">latent_dim</span><span class="p">,</span> <span class="n">conv_flts</span><span class="p">,</span> <span class="n">fusion_level</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span> <span class="n">batch_norm</span><span class="p">,</span>
                <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">decoder</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">decoder</span> <span class="o">=</span> <span class="n">SphericalHemiFusionDecoder</span><span class="p">(</span>
                <span class="n">input_channels</span><span class="p">,</span> <span class="n">input_order</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">,</span> <span class="n">conv_flts</span><span class="p">,</span>
                <span class="n">fusion_level</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span> <span class="n">batch_norm</span><span class="p">,</span> <span class="n">conv_mode</span><span class="p">,</span>
                <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">cachedir</span><span class="o">=</span><span class="n">cachedir</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">decoder</span>

<div class="viewcode-block" id="SphericalVAE.encode">
<a class="viewcode-back" href="../../../generated/surfify.models.vae.SphericalVAE.html#surfify.models.SphericalVAE.encode">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">left_x</span><span class="p">,</span> <span class="n">right_x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; The encoder.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        left_x: Tensor (samples, &lt;input_channels&gt;, azimuth, elevation)</span>
<span class="sd">            input left cortical texture.</span>
<span class="sd">        right_x: Tensor (samples, &lt;input_channels&gt;, azimuth, elevation)</span>
<span class="sd">            input right cortical texture.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        q(z | x): Normal (batch_size, &lt;latent_dim&gt;)</span>
<span class="sd">            a Normal distribution.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">((</span><span class="n">left_x</span><span class="p">,</span> <span class="n">right_x</span><span class="p">))</span>
        <span class="n">z_mu</span><span class="p">,</span> <span class="n">z_logvar</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">chunks</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">z_mu</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="p">(</span><span class="n">z_logvar</span> <span class="o">*</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">exp</span><span class="p">())</span></div>


<div class="viewcode-block" id="SphericalVAE.decode">
<a class="viewcode-back" href="../../../generated/surfify.models.vae.SphericalVAE.html#surfify.models.SphericalVAE.decode">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; The decoder.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        z: Tensor (samples, &lt;latent_dim&gt;)</span>
<span class="sd">            the stochastic latent state z.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        left_recon_x: Tensor (samples, &lt;input_channels&gt;, n_vertices)</span>
<span class="sd">            reconstructed left cortical texture.</span>
<span class="sd">        right_recon_x: Tensor (samples, &lt;input_channels&gt;, n_vertices)</span>
<span class="sd">            reconstructed right cortical texture.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">left_recon_x</span><span class="p">,</span> <span class="n">right_recon_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">left_recon_x</span><span class="p">,</span> <span class="n">right_recon_x</span></div>


<div class="viewcode-block" id="SphericalVAE.reparameterize">
<a class="viewcode-back" href="../../../generated/surfify.models.vae.SphericalVAE.html#surfify.models.SphericalVAE.reparameterize">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">reparameterize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">sample</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Implement the reparametrization trick.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">sample</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">q</span><span class="o">.</span><span class="n">rsample</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">q</span><span class="o">.</span><span class="n">loc</span></div>


<div class="viewcode-block" id="SphericalVAE.forward">
<a class="viewcode-back" href="../../../generated/surfify.models.vae.SphericalVAE.html#surfify.models.SphericalVAE.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">left_x</span><span class="p">,</span> <span class="n">right_x</span><span class="p">,</span> <span class="n">sample</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; The forward method.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        left_x: Tensor (samples, &lt;input_channels&gt;, azimuth, elevation)</span>
<span class="sd">            input left cortical texture.</span>
<span class="sd">        right_x: Tensor (samples, &lt;input_channels&gt;, azimuth, elevation)</span>
<span class="sd">            input right cortical texture.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        left_recon_x: Tensor (samples, &lt;input_channels&gt;, azimuth, elevation)</span>
<span class="sd">            reconstructed left cortical texture.</span>
<span class="sd">        right_recon_x: Tensor (samples, &lt;input_channels&gt;, azimuth, elevation)</span>
<span class="sd">            reconstructed right cortical texture.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;SphericalVAE forward pass&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">debug_msg</span><span class="p">(</span><span class="s2">&quot;left cortical&quot;</span><span class="p">,</span> <span class="n">left_x</span><span class="p">))</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">debug_msg</span><span class="p">(</span><span class="s2">&quot;right cortical&quot;</span><span class="p">,</span> <span class="n">right_x</span><span class="p">))</span>
        <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">left_x</span><span class="p">,</span> <span class="n">right_x</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">debug_msg</span><span class="p">(</span><span class="s2">&quot;posterior loc&quot;</span><span class="p">,</span> <span class="n">q</span><span class="o">.</span><span class="n">loc</span><span class="p">))</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">debug_msg</span><span class="p">(</span><span class="s2">&quot;posterior scale&quot;</span><span class="p">,</span> <span class="n">q</span><span class="o">.</span><span class="n">scale</span><span class="p">))</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reparameterize</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">sample</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">debug_msg</span><span class="p">(</span><span class="s2">&quot;z&quot;</span><span class="p">,</span> <span class="n">z</span><span class="p">))</span>
        <span class="n">left_recon_x</span><span class="p">,</span> <span class="n">right_recon_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">debug_msg</span><span class="p">(</span><span class="s2">&quot;left recon cortical&quot;</span><span class="p">,</span> <span class="n">left_recon_x</span><span class="p">))</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">debug_msg</span><span class="p">(</span><span class="s2">&quot;right recon cortical&quot;</span><span class="p">,</span> <span class="n">right_recon_x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">left_recon_x</span><span class="p">,</span> <span class="n">right_recon_x</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;q&quot;</span><span class="p">:</span> <span class="n">q</span><span class="p">,</span> <span class="s2">&quot;z&quot;</span><span class="p">:</span> <span class="n">z</span><span class="p">}</span></div>
</div>



<div class="viewcode-block" id="SphericalHemiFusionEncoder">
<a class="viewcode-back" href="../../../generated/surfify.models.vae.SphericalHemiFusionEncoder.html#surfify.models.SphericalHemiFusionEncoder">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">SphericalHemiFusionEncoder</span><span class="p">(</span><span class="n">SphericalBase</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_channels</span><span class="p">,</span> <span class="n">input_order</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">,</span>
                 <span class="n">conv_flts</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span> <span class="n">fusion_level</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;LeakyReLU&quot;</span><span class="p">,</span> <span class="n">batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">conv_mode</span><span class="o">=</span><span class="s2">&quot;DiNe&quot;</span><span class="p">,</span> <span class="n">dine_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">repa_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">repa_zoom</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                 <span class="n">dynamic_repa_zoom</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">standard_ico</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">cachedir</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Init class.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        input_channels: int, default 1</span>
<span class="sd">            the number of input channels.</span>
<span class="sd">        input_dim: int, default 192</span>
<span class="sd">            the size of the converted 3-D surface to the 2-D grid.</span>
<span class="sd">        latent_dim: int, default 64</span>
<span class="sd">            the size of the latent space it encodes to.</span>
<span class="sd">        conv_flts: list of int</span>
<span class="sd">            the size of convolutional filters.</span>
<span class="sd">        fusion_level: int, default 1</span>
<span class="sd">            at which max pooling level left and right hemisphere data</span>
<span class="sd">            are concatenated.</span>
<span class="sd">        activation: str, default &#39;LeakyReLU&#39;</span>
<span class="sd">            activation function&#39;s class name in pytorch&#39;s nn module to use</span>
<span class="sd">            after each convolution</span>
<span class="sd">        batch_norm: bool, default False</span>
<span class="sd">            optionally uses batch normalization after each convolution</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;SphericalHemiFusionEncoder init...&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">input_order</span><span class="o">=</span><span class="n">input_order</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">conv_flts</span><span class="p">),</span>
            <span class="n">conv_mode</span><span class="o">=</span><span class="n">conv_mode</span><span class="p">,</span> <span class="n">dine_size</span><span class="o">=</span><span class="n">dine_size</span><span class="p">,</span> <span class="n">repa_size</span><span class="o">=</span><span class="n">repa_size</span><span class="p">,</span>
            <span class="n">repa_zoom</span><span class="o">=</span><span class="n">repa_zoom</span><span class="p">,</span> <span class="n">dynamic_repa_zoom</span><span class="o">=</span><span class="n">dynamic_repa_zoom</span><span class="p">,</span>
            <span class="n">standard_ico</span><span class="o">=</span><span class="n">standard_ico</span><span class="p">,</span> <span class="n">cachedir</span><span class="o">=</span><span class="n">cachedir</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_channels</span> <span class="o">=</span> <span class="n">input_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_flts</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">conv_flts</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">nn</span><span class="p">,</span> <span class="n">activation</span><span class="p">)(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_vertices_down</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ico</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">input_order</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">]</span><span class="o">.</span><span class="n">vertices</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;  number of vertices small ico : </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_vertices_down</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flatten_dim</span> <span class="o">=</span> <span class="n">conv_flts</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_vertices_down</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;  dimension for linear </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flatten_dim</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">fusion_level</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="ow">or</span> <span class="n">fusion_level</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Impossible to use input fusion level with &quot;</span>
                             <span class="s2">&quot;&#39;</span><span class="si">{0}</span><span class="s2">&#39; layers.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fusion_level</span> <span class="o">=</span> <span class="n">fusion_level</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">latent_dim</span> <span class="o">=</span> <span class="n">latent_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">left_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">right_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
        <span class="n">input_channels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_channels</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">):</span>
            <span class="n">order</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_order</span> <span class="o">-</span> <span class="n">idx</span>
            <span class="n">output_channels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_flts</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
            <span class="n">pooling</span> <span class="o">=</span> <span class="n">IcoPool</span><span class="p">(</span>
                <span class="n">down_neigh_indices</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ico</span><span class="p">[</span><span class="n">order</span><span class="p">]</span><span class="o">.</span><span class="n">neighbor_indices</span><span class="p">,</span>
                <span class="n">down_indices</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ico</span><span class="p">[</span><span class="n">order</span><span class="p">]</span><span class="o">.</span><span class="n">down_indices</span><span class="p">,</span>
                <span class="n">pooling_type</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="n">fusion_level</span><span class="p">:</span>
                <span class="n">output_channels</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">output_channels</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
                <span class="n">lconv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sconv</span><span class="p">(</span>
                    <span class="n">input_channels</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">ico</span><span class="p">[</span><span class="n">order</span><span class="p">]</span><span class="o">.</span><span class="n">conv_neighbor_indices</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">left_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;l_conv_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span> <span class="n">lconv</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">batch_norm</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">left_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span>
                        <span class="s2">&quot;l_bn_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span>
                        <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">output_channels</span><span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">left_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;pooling_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span> <span class="n">pooling</span><span class="p">)</span>
                <span class="n">rconv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sconv</span><span class="p">(</span>
                    <span class="n">input_channels</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">ico</span><span class="p">[</span><span class="n">order</span><span class="p">]</span><span class="o">.</span><span class="n">conv_neighbor_indices</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">right_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;r_conv_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span> <span class="n">rconv</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">batch_norm</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">right_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span>
                        <span class="s2">&quot;r_bn_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span>
                        <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">output_channels</span><span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">right_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;pooling_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span> <span class="n">pooling</span><span class="p">)</span>
                <span class="n">input_channels</span> <span class="o">=</span> <span class="n">output_channels</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">input_channels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_flts</span><span class="p">[</span><span class="n">idx</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
                <span class="n">conv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sconv</span><span class="p">(</span>
                    <span class="n">input_channels</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">ico</span><span class="p">[</span><span class="n">order</span><span class="p">]</span><span class="o">.</span><span class="n">conv_neighbor_indices</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">w_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;conv_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span> <span class="n">conv</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">batch_norm</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">w_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span>
                        <span class="s2">&quot;bn_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span>
                        <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_flts</span><span class="p">[</span><span class="n">idx</span><span class="p">]))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">w_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;pooling_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span> <span class="n">pooling</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w_dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flatten_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">latent_dim</span><span class="p">)</span>

<div class="viewcode-block" id="SphericalHemiFusionEncoder.forward">
<a class="viewcode-back" href="../../../generated/surfify.models.vae.SphericalHemiFusionEncoder.html#surfify.models.SphericalHemiFusionEncoder.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; The encoding.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        left_x: Tensor (batch_size, &lt;input_channels&gt;, n_vertices)</span>
<span class="sd">            input left cortical textures.</span>
<span class="sd">        right_x: Tensor (batch_size, &lt;input_channels&gt;, n_vertices)</span>
<span class="sd">            input right cortical textures.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        x: Tensor (batch_size, &lt;latent_dim&gt;)</span>
<span class="sd">            the latent representations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">left_x</span><span class="p">,</span> <span class="n">right_x</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;SphericalHemiFusionEncoder forward pass&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">debug_msg</span><span class="p">(</span><span class="s2">&quot;  left cortical&quot;</span><span class="p">,</span> <span class="n">left_x</span><span class="p">))</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">debug_msg</span><span class="p">(</span><span class="s2">&quot;  right cortical&quot;</span><span class="p">,</span> <span class="n">right_x</span><span class="p">))</span>
        <span class="n">left_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_safe_forward</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">left_conv</span><span class="p">,</span> <span class="n">left_x</span><span class="p">,</span> <span class="n">act</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">,</span> <span class="n">skip_last_act</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">right_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_safe_forward</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">right_conv</span><span class="p">,</span> <span class="n">right_x</span><span class="p">,</span> <span class="n">act</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">,</span> <span class="n">skip_last_act</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">debug_msg</span><span class="p">(</span><span class="s2">&quot;  left enc&quot;</span><span class="p">,</span> <span class="n">left_x</span><span class="p">))</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">debug_msg</span><span class="p">(</span><span class="s2">&quot;  right enc&quot;</span><span class="p">,</span> <span class="n">right_x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">left_x</span><span class="p">,</span> <span class="n">right_x</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">debug_msg</span><span class="p">(</span><span class="s2">&quot;  merged enc&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_safe_forward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w_conv</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">act</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">debug_msg</span><span class="p">(</span><span class="s2">&quot;  final conv enc&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten_dim</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">debug_msg</span><span class="p">(</span><span class="s2">&quot;  flattened&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_dense</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span></div>
</div>



<div class="viewcode-block" id="SphericalHemiFusionDecoder">
<a class="viewcode-back" href="../../../generated/surfify.models.vae.SphericalHemiFusionDecoder.html#surfify.models.SphericalHemiFusionDecoder">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">SphericalHemiFusionDecoder</span><span class="p">(</span><span class="n">SphericalBase</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_channels</span><span class="p">,</span> <span class="n">input_order</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">,</span>
                 <span class="n">conv_flts</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span> <span class="n">fusion_level</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;LeakyReLU&quot;</span><span class="p">,</span> <span class="n">batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">conv_mode</span><span class="o">=</span><span class="s2">&quot;DiNe&quot;</span><span class="p">,</span> <span class="n">dine_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">repa_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">repa_zoom</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                 <span class="n">dynamic_repa_zoom</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">standard_ico</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">cachedir</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Init class.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        input_channels: int, default 1</span>
<span class="sd">            the number of input channels.</span>
<span class="sd">        input_dim: int, default 192</span>
<span class="sd">            the size of the converted 3-D surface to the 2-D grid.</span>
<span class="sd">        latent_dim: int, default 64</span>
<span class="sd">            the size of the latent space it encodes to.</span>
<span class="sd">        conv_flts: list of int</span>
<span class="sd">            the size of convolutional filters.</span>
<span class="sd">        fusion_level: int, default 1</span>
<span class="sd">            at which max pooling level left and right hemisphere data</span>
<span class="sd">            are concatenated.</span>
<span class="sd">        activation: str, default &#39;LeakyReLU&#39;</span>
<span class="sd">            activation function&#39;s class name in pytorch&#39;s nn module to use</span>
<span class="sd">            after each convolution</span>
<span class="sd">        batch_norm: bool, default False</span>
<span class="sd">            optionally uses batch normalization after each convolution</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;SphericalHemiFusionDecoder init...&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">input_order</span><span class="o">=</span><span class="n">input_order</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">conv_flts</span><span class="p">),</span>
            <span class="n">conv_mode</span><span class="o">=</span><span class="n">conv_mode</span><span class="p">,</span> <span class="n">dine_size</span><span class="o">=</span><span class="n">dine_size</span><span class="p">,</span> <span class="n">repa_size</span><span class="o">=</span><span class="n">repa_size</span><span class="p">,</span>
            <span class="n">repa_zoom</span><span class="o">=</span><span class="n">repa_zoom</span><span class="p">,</span> <span class="n">dynamic_repa_zoom</span><span class="o">=</span><span class="n">dynamic_repa_zoom</span><span class="p">,</span>
            <span class="n">standard_ico</span><span class="o">=</span><span class="n">standard_ico</span><span class="p">,</span> <span class="n">cachedir</span><span class="o">=</span><span class="n">cachedir</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_channels</span> <span class="o">=</span> <span class="n">input_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">latent_dim</span> <span class="o">=</span> <span class="n">latent_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_flts</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">conv_flts</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">nn</span><span class="p">,</span> <span class="n">activation</span><span class="p">)(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_vertices_down</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ico</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">input_order</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">]</span><span class="o">.</span><span class="n">vertices</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;  number of vertices small ico : </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_vertices_down</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flatten_dim</span> <span class="o">=</span> <span class="n">conv_flts</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_vertices_down</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;  dimension for linear </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flatten_dim</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">fusion_level</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="ow">or</span> <span class="n">fusion_level</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Impossible to use input fusion level with &quot;</span>
                             <span class="s2">&quot;&#39;</span><span class="si">{0}</span><span class="s2">&#39; layers.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fusion_level</span> <span class="o">=</span> <span class="n">fusion_level</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">latent_dim</span> <span class="o">=</span> <span class="n">latent_dim</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">w_dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">latent_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">left_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">right_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
        <span class="n">input_channels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_flts</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">order</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_order</span> <span class="o">-</span> <span class="n">idx</span> <span class="o">-</span> <span class="mi">1</span>
            <span class="n">input_channels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_flts</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
            <span class="n">output_channels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_channels</span> <span class="o">*</span> <span class="mi">2</span>
            <span class="k">if</span> <span class="n">idx</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">output_channels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_flts</span><span class="p">[</span><span class="n">idx</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="n">fusion_level</span><span class="p">:</span>
                <span class="n">output_channels</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">output_channels</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
                <span class="n">input_channels</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">input_channels</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;input channels : </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">input_channels</span><span class="p">))</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;output channels : </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">output_channels</span><span class="p">))</span>
                <span class="n">l_pooling</span> <span class="o">=</span> <span class="n">IcoUpConv</span><span class="p">(</span>
                    <span class="n">in_feats</span><span class="o">=</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">out_feats</span><span class="o">=</span><span class="n">output_channels</span><span class="p">,</span>
                    <span class="n">up_neigh_indices</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ico</span><span class="p">[</span><span class="n">order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">neighbor_indices</span><span class="p">,</span>
                    <span class="n">down_indices</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ico</span><span class="p">[</span><span class="n">order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">down_indices</span><span class="p">)</span>
                <span class="n">lconv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sconv</span><span class="p">(</span>
                    <span class="n">output_channels</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">ico</span><span class="p">[</span><span class="n">order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">conv_neighbor_indices</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">left_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span>
                    <span class="s2">&quot;l_pooling_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span> <span class="n">l_pooling</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">left_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;l_conv_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span> <span class="n">lconv</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">batch_norm</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">left_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span>
                        <span class="s2">&quot;l_bn_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span>
                        <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">output_channels</span><span class="p">))</span>
                <span class="n">r_pooling</span> <span class="o">=</span> <span class="n">IcoUpConv</span><span class="p">(</span>
                    <span class="n">in_feats</span><span class="o">=</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">out_feats</span><span class="o">=</span><span class="n">output_channels</span><span class="p">,</span>
                    <span class="n">up_neigh_indices</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ico</span><span class="p">[</span><span class="n">order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">neighbor_indices</span><span class="p">,</span>
                    <span class="n">down_indices</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ico</span><span class="p">[</span><span class="n">order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">down_indices</span><span class="p">)</span>
                <span class="n">rconv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sconv</span><span class="p">(</span>
                    <span class="n">output_channels</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">ico</span><span class="p">[</span><span class="n">order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">conv_neighbor_indices</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">right_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span>
                    <span class="s2">&quot;r_pooling_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span> <span class="n">r_pooling</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">right_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;r_conv_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span> <span class="n">rconv</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">batch_norm</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">right_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span>
                        <span class="s2">&quot;r_bn_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span>
                        <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">output_channels</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;input channels : </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">input_channels</span><span class="p">))</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;output channels : </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">output_channels</span><span class="p">))</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;order : </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">order</span><span class="p">))</span>
                <span class="n">pooling</span> <span class="o">=</span> <span class="n">IcoUpConv</span><span class="p">(</span>
                    <span class="n">in_feats</span><span class="o">=</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">out_feats</span><span class="o">=</span><span class="n">output_channels</span><span class="p">,</span>
                    <span class="n">up_neigh_indices</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ico</span><span class="p">[</span><span class="n">order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">neighbor_indices</span><span class="p">,</span>
                    <span class="n">down_indices</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ico</span><span class="p">[</span><span class="n">order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">down_indices</span><span class="p">)</span>
                <span class="n">conv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sconv</span><span class="p">(</span>
                    <span class="n">output_channels</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">ico</span><span class="p">[</span><span class="n">order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">conv_neighbor_indices</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">w_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;pooling_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span> <span class="n">pooling</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">w_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;conv_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span> <span class="n">conv</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">batch_norm</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">w_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span>
                        <span class="s2">&quot;bn_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span>
                        <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_flts</span><span class="p">[</span><span class="n">idx</span><span class="p">]))</span>

<div class="viewcode-block" id="SphericalHemiFusionDecoder.forward">
<a class="viewcode-back" href="../../../generated/surfify.models.vae.SphericalHemiFusionDecoder.html#surfify.models.SphericalHemiFusionDecoder.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; The decoding.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        left_x: Tensor (batch_size, &lt;input_channels&gt;, n_vertices)</span>
<span class="sd">            input left cortical textures.</span>
<span class="sd">        right_x: Tensor (batch_size, &lt;input_channels&gt;, n_vertices)</span>
<span class="sd">            input right cortical textures.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        x: Tensor (batch_size, &lt;latent_dim&gt;)</span>
<span class="sd">            the latent representations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;SphericalHemiFusionDecoder forward pass&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">debug_msg</span><span class="p">(</span><span class="s2">&quot;latent&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w_dense</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_flts</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_vertices_down</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">debug_msg</span><span class="p">(</span><span class="s2">&quot;input to conv&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_safe_forward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w_conv</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">act</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">debug_msg</span><span class="p">(</span><span class="s2">&quot;before hemi sep&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
        <span class="n">left_x</span><span class="p">,</span> <span class="n">right_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">chunks</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">debug_msg</span><span class="p">(</span><span class="s2">&quot;after hemi sep right&quot;</span><span class="p">,</span> <span class="n">right_x</span><span class="p">))</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">debug_msg</span><span class="p">(</span><span class="s2">&quot;after hemi sep left&quot;</span><span class="p">,</span> <span class="n">left_x</span><span class="p">))</span>
        <span class="n">left_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_safe_forward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">left_conv</span><span class="p">,</span> <span class="n">left_x</span><span class="p">,</span>
                                    <span class="n">act</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">,</span> <span class="n">skip_last_act</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">right_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_safe_forward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">right_conv</span><span class="p">,</span> <span class="n">right_x</span><span class="p">,</span>
                                     <span class="n">act</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">,</span> <span class="n">skip_last_act</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">left_x</span><span class="p">,</span> <span class="n">right_x</span></div>
</div>



<div class="viewcode-block" id="compute_output_dim">
<a class="viewcode-back" href="../../../generated/surfify.models.vae.compute_output_dim.html#surfify.models.compute_output_dim">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">compute_output_dim</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">convnet</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Compute the output dimension of a convolutional network</span>
<span class="sd">    that takes as input a square input (H = W)</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    input_dim: int</span>
<span class="sd">        input height and weight</span>
<span class="sd">    convnet: iterable[nn.Module]</span>
<span class="sd">        iterable containing the various layers. For now, the function</span>
<span class="sd">        can only work with nn.Conv2d and IcoSpMaConv layers</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    output_dim: int</span>
<span class="sd">        output dimension</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">output_dim</span> <span class="o">=</span> <span class="n">input_dim</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">convnet</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span> <span class="ow">is</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">:</span>
            <span class="n">output_dim</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span>
                <span class="p">(</span><span class="n">output_dim</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">layer</span><span class="o">.</span><span class="n">padding</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">layer</span><span class="o">.</span><span class="n">dilation</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span>
                 <span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">type</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span> <span class="ow">is</span> <span class="n">IcoSpMaConv</span><span class="p">:</span>
            <span class="n">output_dim</span> <span class="o">=</span> <span class="n">compute_output_dim</span><span class="p">(</span>
                <span class="n">output_dim</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">layer</span><span class="o">.</span><span class="n">pad</span><span class="p">,</span> <span class="p">[</span><span class="n">layer</span><span class="o">.</span><span class="n">conv</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">output_dim</span></div>



<div class="viewcode-block" id="HemiFusionEncoder">
<a class="viewcode-back" href="../../../generated/surfify.models.vae.HemiFusionEncoder.html#surfify.models.HemiFusionEncoder">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">HemiFusionEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_channels</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">,</span>
                 <span class="n">conv_flts</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span> <span class="n">fusion_level</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;LeakyReLU&quot;</span><span class="p">,</span> <span class="n">batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Init class.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        input_channels: int, default 1</span>
<span class="sd">            the number of input channels.</span>
<span class="sd">        input_dim: int, default 192</span>
<span class="sd">            the size of the converted 3-D surface to the 2-D grid.</span>
<span class="sd">        latent_dim: int, default 64</span>
<span class="sd">            the size of the latent space it encodes to.</span>
<span class="sd">        conv_flts: list of int</span>
<span class="sd">            the size of convolutional filters.</span>
<span class="sd">        fusion_level: int, default 1</span>
<span class="sd">            at which max pooling level left and right hemisphere data</span>
<span class="sd">            are concatenated.</span>
<span class="sd">        activation: str, default &#39;LeakyReLU&#39;</span>
<span class="sd">            activation function&#39;s class name in pytorch&#39;s nn module to use</span>
<span class="sd">            after each convolution</span>
<span class="sd">        batch_norm: bool, default False</span>
<span class="sd">            optionally uses batch normalization after each convolution</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;HemiFusionEncoder init...&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_channels</span> <span class="o">=</span> <span class="n">input_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">input_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">latent_dim</span> <span class="o">=</span> <span class="n">latent_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_flts</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">conv_flts</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_flts</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">fusion_level</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="ow">or</span> <span class="n">fusion_level</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Impossible to use input fusion level with &quot;</span>
                             <span class="s2">&quot;&#39;</span><span class="si">{0}</span><span class="s2">&#39; layers.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fusion_level</span> <span class="o">=</span> <span class="n">fusion_level</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">left_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">right_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
        <span class="n">input_channels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_channels</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">8</span>
                <span class="n">pad</span> <span class="o">=</span> <span class="mi">3</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">4</span>
                <span class="n">pad</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="n">output_channels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_flts</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="n">fusion_level</span><span class="p">:</span>
                <span class="n">output_channels</span> <span class="o">/=</span> <span class="mi">2</span>
                <span class="n">lconv</span> <span class="o">=</span> <span class="n">IcoSpMaConv</span><span class="p">(</span>
                    <span class="n">in_feats</span><span class="o">=</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">out_feats</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">output_channels</span><span class="p">),</span>
                    <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="n">pad</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">left_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;l_conv_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span> <span class="n">lconv</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">batch_norm</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">left_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span>
                        <span class="s2">&quot;l_bn_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span>
                        <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">output_channels</span><span class="p">)))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">left_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span>
                    <span class="s2">&quot;l_act_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span>
                    <span class="nb">getattr</span><span class="p">(</span><span class="n">nn</span><span class="p">,</span> <span class="n">activation</span><span class="p">)(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
                <span class="n">rconv</span> <span class="o">=</span> <span class="n">IcoSpMaConv</span><span class="p">(</span>
                    <span class="n">in_feats</span><span class="o">=</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">out_feats</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">output_channels</span><span class="p">),</span>
                    <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="n">pad</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">right_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;r_conv_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span> <span class="n">rconv</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">batch_norm</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">right_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span>
                        <span class="s2">&quot;r_bn_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span>
                        <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">output_channels</span><span class="p">)))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">right_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span>
                    <span class="s2">&quot;r_act_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span>
                    <span class="nb">getattr</span><span class="p">(</span><span class="n">nn</span><span class="p">,</span> <span class="n">activation</span><span class="p">)(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
                <span class="n">input_channels</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">output_channels</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">input_channels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_flts</span><span class="p">[</span><span class="n">idx</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
                <span class="n">conv</span> <span class="o">=</span> <span class="n">IcoSpMaConv</span><span class="p">(</span>
                    <span class="n">in_feats</span><span class="o">=</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">out_feats</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_flts</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                    <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="n">pad</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">w_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;conv_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span> <span class="n">conv</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">batch_norm</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">w_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span>
                        <span class="s2">&quot;bn_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span>
                        <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_flts</span><span class="p">[</span><span class="n">idx</span><span class="p">]))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">w_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;act_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span>
                                       <span class="nb">getattr</span><span class="p">(</span><span class="n">nn</span><span class="p">,</span> <span class="n">activation</span><span class="p">)(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="n">compute_output_dim</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span>
                                             <span class="p">[</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">left_conv</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">w_conv</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flatten_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_flts</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w_dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flatten_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">latent_dim</span><span class="p">)</span>

<div class="viewcode-block" id="HemiFusionEncoder.forward">
<a class="viewcode-back" href="../../../generated/surfify.models.vae.HemiFusionEncoder.html#surfify.models.HemiFusionEncoder.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; The encoder.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        left_x: Tensor (samples, &lt;input_channels&gt;, azimuth, elevation)</span>
<span class="sd">            input left cortical texture.</span>
<span class="sd">        right_x: Tensor (samples, &lt;input_channels&gt;, azimuth, elevation)</span>
<span class="sd">            input right cortical texture.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        q(z | x): Normal (batch_size, &lt;latent_dim&gt;)</span>
<span class="sd">            a Normal distribution.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">left_x</span><span class="p">,</span> <span class="n">right_x</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">left_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">left_conv</span><span class="p">(</span><span class="n">left_x</span><span class="p">)</span>
        <span class="n">right_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">right_conv</span><span class="p">(</span><span class="n">right_x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">left_x</span><span class="p">,</span> <span class="n">right_x</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten_dim</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_dense</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span></div>
</div>



<div class="viewcode-block" id="HemiFusionDecoder">
<a class="viewcode-back" href="../../../generated/surfify.models.vae.HemiFusionDecoder.html#surfify.models.HemiFusionDecoder">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">HemiFusionDecoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_shape</span><span class="p">,</span> <span class="n">before_latent_dim</span><span class="p">,</span>
                 <span class="n">latent_dim</span><span class="p">,</span> <span class="n">conv_flts</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
                 <span class="n">fusion_level</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;LeakyReLU&quot;</span><span class="p">,</span> <span class="n">batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Init class.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        output_channels: int, default 1</span>
<span class="sd">            the number of output channels.</span>
<span class="sd">        input_dim: int,</span>
<span class="sd">            the size of the squared input to the convnet, after the dense</span>
<span class="sd">            layer transforming the input from the latent space.</span>
<span class="sd">        latent_dim: int, default 64</span>
<span class="sd">            the size of the latent space it decodes from.</span>
<span class="sd">        conv_flts: list of int</span>
<span class="sd">            the size of convolutional filters, given in reverse order: the</span>
<span class="sd">            first filter in the list will be the last one in the network.</span>
<span class="sd">        fusion_level: int, default 1</span>
<span class="sd">            at which max pooling level left and right hemisphere data</span>
<span class="sd">            are concatenated.</span>
<span class="sd">        activation: str, default &#39;LeakyReLU&#39;</span>
<span class="sd">            activation function&#39;s class name in pytorch&#39;s nn module to use</span>
<span class="sd">            after each convolution</span>
<span class="sd">        batch_norm: bool, default False</span>
<span class="sd">            optionally uses batch normalization after each convolution</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;HemiFusionDecoder init...&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">before_latent_dim</span> <span class="o">=</span> <span class="n">before_latent_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_flts</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">conv_flts</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">conv_flts</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_flts</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">output_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_shape</span> <span class="o">=</span> <span class="n">output_shape</span>
        <span class="c1"># flatten_dim = input_dim ** 2 * conv_flts[-1]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w_dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">before_latent_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">left_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">right_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fusion_level</span> <span class="o">=</span> <span class="n">fusion_level</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">4</span>
            <span class="n">pad</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="n">zero_pad</span> <span class="o">=</span> <span class="mi">3</span>
            <span class="n">output_shape</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="n">idx</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">8</span>
                <span class="n">pad</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="n">zero_pad</span> <span class="o">=</span> <span class="mi">5</span> <span class="o">-</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">%</span> <span class="mi">8</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
                <span class="n">output_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_shape</span>

            <span class="n">input_channels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_flts</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
            <span class="n">output_channels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_flts</span><span class="p">[</span><span class="n">idx</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="n">fusion_level</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">input_channels</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">input_channels</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
                <span class="n">output_channels</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">output_channels</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
                <span class="n">lconv</span> <span class="o">=</span> <span class="n">IcoSpMaConvTranspose</span><span class="p">(</span>
                    <span class="n">in_feats</span><span class="o">=</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">out_feats</span><span class="o">=</span><span class="n">output_channels</span><span class="p">,</span>
                    <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="n">pad</span><span class="p">,</span>
                    <span class="n">zero_pad</span><span class="o">=</span><span class="n">zero_pad</span><span class="p">,</span> <span class="n">output_shape</span><span class="o">=</span><span class="n">output_shape</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">batch_norm</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">left_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span>
                        <span class="s2">&quot;l_bn_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span>
                        <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">input_channels</span><span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">left_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;l_act_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span>
                                          <span class="nb">getattr</span><span class="p">(</span><span class="n">nn</span><span class="p">,</span> <span class="n">activation</span><span class="p">)())</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">left_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;l_conv_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span> <span class="n">lconv</span><span class="p">)</span>
                <span class="n">rconv</span> <span class="o">=</span> <span class="n">IcoSpMaConvTranspose</span><span class="p">(</span>
                    <span class="n">in_feats</span><span class="o">=</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">out_feats</span><span class="o">=</span><span class="n">output_channels</span><span class="p">,</span>
                    <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="n">pad</span><span class="p">,</span>
                    <span class="n">zero_pad</span><span class="o">=</span><span class="n">zero_pad</span><span class="p">,</span> <span class="n">output_shape</span><span class="o">=</span><span class="n">output_shape</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">batch_norm</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">right_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span>
                        <span class="s2">&quot;r_bn_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span>
                        <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">input_channels</span><span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">right_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;r_act_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span>
                                           <span class="nb">getattr</span><span class="p">(</span><span class="n">nn</span><span class="p">,</span> <span class="n">activation</span><span class="p">)())</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">right_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;r_conv_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span> <span class="n">rconv</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">conv</span> <span class="o">=</span> <span class="n">IcoSpMaConvTranspose</span><span class="p">(</span>
                    <span class="n">input_channels</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span>
                    <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="n">pad</span><span class="p">,</span> <span class="n">zero_pad</span><span class="o">=</span><span class="n">zero_pad</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">batch_norm</span> <span class="ow">and</span> <span class="n">idx</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">w_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span>
                        <span class="s2">&quot;bn_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span>
                        <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">output_channels</span><span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">w_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;act_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span>
                                       <span class="nb">getattr</span><span class="p">(</span><span class="n">nn</span><span class="p">,</span> <span class="n">activation</span><span class="p">)(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">w_conv</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;conv_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span> <span class="n">conv</span><span class="p">)</span>

<div class="viewcode-block" id="HemiFusionDecoder.forward">
<a class="viewcode-back" href="../../../generated/surfify.models.vae.HemiFusionDecoder.html#surfify.models.HemiFusionDecoder.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; The decoder.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        z: Tensor (samples, &lt;latent_dim&gt;)</span>
<span class="sd">            the stochastic latent state z.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        left_recon_x: Tensor (samples, &lt;input_channels&gt;, azimuth, elevation)</span>
<span class="sd">            reconstructed left cortical texture.</span>
<span class="sd">        right_recon_x: Tensor (samples, &lt;input_channels&gt;, azimuth, elevation)</span>
<span class="sd">            reconstructed right cortical texture.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_dense</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">remaining_shape</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">sqrt</span><span class="p">(</span>
            <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_flts</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_flts</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">remaining_shape</span><span class="p">,</span>
                   <span class="n">remaining_shape</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">left_recon_x</span><span class="p">,</span> <span class="n">right_recon_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">chunks</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">left_recon_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">left_conv</span><span class="p">(</span><span class="n">left_recon_x</span><span class="p">)</span>
        <span class="n">right_recon_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">right_conv</span><span class="p">(</span><span class="n">right_recon_x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">left_recon_x</span><span class="p">,</span> <span class="n">right_recon_x</span></div>
</div>

</pre></div>
                    </div>
                <div class="spacer"></div>
		        
		        <!-- Footer -->
		        <div class="section-6-container section-container section-container-image-bg" id="section-6">
			        <div class="container">
			            <div class="row">
		                    <div class="col-md-5 offset-md-1 section-6-box wow fadeInDown">
                                <div class="section-6-title">
		                    	    <p>Follow us</p>
                                </div>
		                    	<div class="section-6-social">
			                    	<a href="https://www.facebook.com/pages/NeuroSpin/171075046414933"><i class="fab fa-facebook-f"></i></a>
									<a href="https://www.youtube.com/CEASaclay"><i class="fab fa-youtube"></i></a>
									<a href="https://twitter.com/neurospin_91"><i class="fab fa-twitter"></i></a>
									<a href="https://github.com/AGrigis/pysphinxdoc"><i class="fab fa-github"></i></a>
                                    <p>&copy; 2025, 
surfify developers
 <antoine.grigis@cea.fr></p>
		                    	</div>
		                    </div>
			            </div>
			        </div>
                </div>
	        
	        </div>
	        <!-- End content -->
        
        </div>
        <!-- End wrapper -->

        <!-- Javascript -->
		<script src="../../../_static/js/jquery-3.3.1.min.js"></script>
		<script src="../../../_static/js/jquery-migrate-3.0.0.min.js"></script>
		<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
		<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
        <script src="../../../_static/js/jquery.backstretch.min.js"></script>
        <script src="../../../_static/js/wow.min.js"></script>
        <script src="../../../_static/js/jquery.waypoints.min.js"></script>
        <script src="../../../_static/js/jquery.mCustomScrollbar.concat.min.js"></script>
        <script src="../../../_static/js/scripts.js"></script>
        <script src="../../../_static/js/jquery.mosaic.js"></script>
        <script src="../../../_static/js/search.js"></script>
        <script type="text/javascript">
	        $('.top-content').backstretch("../../../_static/img/backgrounds/banner1.png");
            $('.section-6-container').backstretch("../../../_static/img/backgrounds/footer1.png");
        </script>

    </body>

</html>